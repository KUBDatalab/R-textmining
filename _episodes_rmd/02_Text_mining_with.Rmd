---
title: "Episode 2 tidytext, stopwords, and sentiment analysis"
teaching: 0
exercises: 0
questions:
- "What is a model?"
objectives:
- "First learning objective. (FIXME)"
keypoints:
- "First key point. Brief Answer to questions. (FIXME)"
---


```{r, include = FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("02-")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
## Understanding our data

We have now successfully loaded in our dataset. Before we start preparing it for analysis, let us inspect the columns to see what the dataset contains
```{r}
head(kina)
```

We see that we have a lot of metadata, including the date of the speech, the start and end time of the speech, the discussed resolutions/law proposals and their classifications into subjects, as well as various personal information about the speaker. The last column is called `Text` and this contains the speech itself

## introduction to tidytext and tokenization
To analyze the speeches we need to make the text tidy. Tidy text refers to a dataset where each text has been split up into the individual words that make up the speech. [insert visualization of how words in one row are split into multiple rows]

Splitting texts, in our case speeches, into individual words is called tokenization [insert visualization of tokenization of a sentence]

Tokenization of text into individual words is necessary for text mining because it allows us to analyze the text closely and in detail, analyses which can later be visualized to understand the patterns of the text. Tokenization is language independent, as long as the language is written in an alphabet or syllabary that uses spaces between words. When tokenizating our text to make it tidy, the metadata that describe the whole speech are carried over to also describe the individual word. Thus we can split the text into individual words but still keep track of who said that word and when they did.

We use the tidytext library for tokenization

## Stopwords
In all natural language texts, frequent words that carry little meaning by themselves are distributed all across the text [insert visualization of sentence(s) where stopwords are highlighted].

The frequent low-meaning words need to be removed because they do not add anything to our understanding of the texts and are just noise

The tm library contains a list of stopwords for Danish, which we'll make into a tibble. We have to specify that the list of stopwrds that we want to call is the list for the Danish language. We also rename the tibble column that contains the stopwords. Note that stopword lists are also available for most major european languages

```{r}
stopwords_dansk <- as_tibble(stopwords(kind = "danish"))
stopwords_dansk <- stopwords_dansk %>% 
  rename(word = value)
```

## Sentiment analysis
Sentiment analysis is a method for calculating the sentiment of a text. To do this, it is necessary to have a list of words that have been assigned to a certain sentiment. This can either be a simple assignation of words into positive and negative, or it can be 


This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
